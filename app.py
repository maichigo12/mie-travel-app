import streamlit as st
import pandas as pd
import torch

from transformers import AutoTokenizer, AutoModelForSequenceClassification

from utils.scoring import calc_spot_scores
from utils.hotel import rank_hotels
from utils.route import solve_tsp, make_google_map_url


# =====================
# åˆæœŸè¨­å®š
# =====================
st.set_page_config(page_title="ä¸‰é‡çœŒ1æ³Š2æ—¥æ—…è¡Œãƒ—ãƒ©ãƒ³", layout="wide")

st.title("ğŸ§³ ä¸‰é‡çœŒ 1æ³Š2æ—¥ è¦³å…‰ãƒ—ãƒ©ãƒ³ææ¡ˆã‚¢ãƒ—ãƒª")


# =====================
# ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
# =====================
import streamlit as st
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

MODEL_NAME = "maichigo/mie-bert-travel"

@st.cache_resource
def load_model():
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)
    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME) 
    model.eval()  # æ¨è«–ãƒ¢ãƒ¼ãƒ‰
    return tokenizer, model

tokenizer, model = load_model()

label_names = ["sea","mountain","nature","history",
               "play","shopping","food","family","rain"]


def predict_labels(text, threshold=0.5):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)

    with torch.no_grad():
        outputs = model(**inputs)

    probs = torch.sigmoid(outputs.logits)[0].cpu().numpy()

    scores = {label_names[i]: float(probs[i]) for i in range(len(label_names))}
    active = [k for k, v in scores.items() if v >= threshold]

    return scores, active



# =====================
# CSV èª­ã¿è¾¼ã¿
# =====================
spots_df = pd.read_csv("data/mie_spot.csv")
hotels_df = pd.read_csv("data/mie_hotel.csv")

NAGOYA = {"name": "åå¤å±‹é§…", "lat": 35.1709, "lon": 136.8815}


# =====================
# UIï¼šæ–‡ç« å…¥åŠ›
# =====================
st.header("â‘  è¡ŒããŸã„æ—…è¡Œã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’å…¥åŠ›")

text = st.text_area(
    "ä¾‹ï¼šé›¨ã®æ—¥ã§ã‚‚å®¶æ—ã§æ¥½ã—ã‚ã‚‹å ´æ‰€ã«è¡ŒããŸã„",
    height=80
)

if not text:
    st.stop()


# =====================
# è¦³å…‰åœ°ã‚¹ã‚³ã‚¢è¨ˆç®—
# =====================
scores, active_labels = predict_labels(text)

st.subheader("ğŸ” æ¨å®šã•ã‚ŒãŸæ—…è¡Œã‚¿ã‚¤ãƒ—")
st.write(active_labels)

spot_ranking = calc_spot_scores(scores, spots_df)
if spot_ranking.empty:
    st.error("æ¡ä»¶ã«åˆã†è¦³å…‰åœ°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    st.stop()

top_spots = spot_ranking.head(4)


# =====================
# è¦³å…‰åœ°è¡¨ç¤º
# =====================
st.header("â‘¡ ãŠã™ã™ã‚è¦³å…‰åœ°")

cols = st.columns(2)
for i, (_, row) in enumerate(top_spots.iterrows()):
    with cols[i % 2]:
        st.subheader(row["spot_name"])
        if "img_url" in row:
            st.image(row["img_url"], use_column_width=True)
        st.write(f"ã‚¹ã‚³ã‚¢ï¼š{row['score']:.2f}")


# =====================
# ãƒ›ãƒ†ãƒ«æ¡ä»¶
# =====================
st.header("â‘¢ å®¿æ³Šæ¡ä»¶")

col1, col2, col3 = st.columns(3)

with col1:
    family = st.checkbox("å®¶æ—å‘ã‘")
    hot_spring = st.checkbox("æ¸©æ³‰")

with col2:
    couple = st.checkbox("ã‚«ãƒƒãƒ—ãƒ«")
    scenic = st.checkbox("æ™¯è‰²ãŒè‰¯ã„")

with col3:
    near_station = st.checkbox("é§…è¿‘")
    shopping = st.checkbox("è²·ã„ç‰©ä¾¿åˆ©")

user_hotel_pref = {
    "family": int(family),
    "couple": int(couple),
    "hot_spring": int(hot_spring),
    "scenic": int(scenic),
    "near_station": int(near_station),
    "shopping": int(shopping)
}

ranked_hotels = rank_hotels(hotels_df, user_hotel_pref)
hotel = ranked_hotels.iloc[0]

st.success(f"ğŸ¨ ãŠã™ã™ã‚å®¿æ³Šæ–½è¨­ï¼š{hotel['name']}ï¼ˆ{hotel['area']}ï¼‰")


# =====================
# Day1 / Day2 åˆ†å‰²
# =====================
day1_df = top_spots.iloc[:2]
day2_df = top_spots.iloc[2:]

hotel_location = {
    "name": hotel["name"],
    "lat": hotel["lat"],
    "lon": hotel["lon"]
}

day1_locations = (
    [NAGOYA] +
    day1_df[["name","lat","lon"]].to_dict("records") +
    [hotel_location]
)

day2_locations = (
    [hotel_location] +
    day2_df[["name","lat","lon"]].to_dict("records") +
    [NAGOYA]
)

day1_route = solve_tsp(day1_locations)
day2_route = solve_tsp(day2_locations)


# =====================
# ãƒ«ãƒ¼ãƒˆè¡¨ç¤º
# =====================
st.header("â‘£ 1æ³Š2æ—¥ãƒ¢ãƒ‡ãƒ«ãƒ«ãƒ¼ãƒˆ")

st.subheader("ğŸ—“ Day1")
st.write(" â†’ ".join(day1_route))
st.markdown(f"[Googleãƒãƒƒãƒ—ã§é–‹ã]({make_google_map_url(day1_route)})")

st.subheader("ğŸ—“ Day2")
st.write(" â†’ ".join(day2_route))
st.markdown(f"[Googleãƒãƒƒãƒ—ã§é–‹ã]({make_google_map_url(day2_route)})")
