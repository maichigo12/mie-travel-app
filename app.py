import streamlit as st
import pandas as pd
import torch
import streamlit.components.v1 as components

from transformers import AutoTokenizer, AutoModelForSequenceClassification

from utils.scoring import calc_spot_scores
from utils.hotel import rank_hotels
from utils.route import solve_tsp, make_google_map_url
# from utils.route import solve_tsp


# =====================
# åˆæœŸè¨­å®š
# =====================
st.set_page_config(page_title="ä¸‰é‡çœŒ1æ³Š2æ—¥æ—…è¡Œãƒ—ãƒ©ãƒ³", layout="wide")

st.title("ğŸ§³ ä¸‰é‡çœŒ 1æ³Š2æ—¥ è¦³å…‰ãƒ—ãƒ©ãƒ³ææ¡ˆã‚¢ãƒ—ãƒª")


# =====================
# ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
# =====================
import streamlit as st
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

MODEL_NAME = "maichigo/mie-bert-travel"

@st.cache_resource
def load_model():
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)
    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME) 
    model.eval()  # æ¨è«–ãƒ¢ãƒ¼ãƒ‰
    return tokenizer, model

tokenizer, model = load_model()

label_names = ["sea","mountain","nature","history",
               "play","shopping","food","family","rain"]

# =====================
# ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ–ãƒ¼ã‚¹ãƒˆé–¢æ•°ï¼ˆâ˜…ã“ã“ã«è¿½åŠ â˜…ï¼‰
# =====================
def adjust_scores_by_keywords(text, scores, label_names):
    """
    ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦ã‚¹ã‚³ã‚¢ã‚’èª¿æ•´ã™ã‚‹é–¢æ•°
    """
    keyword_boost = {
        'sea': ['æµ·', 'ãƒ“ãƒ¼ãƒ', 'æµ·å²¸', 'æ³¢', 'ãƒãƒªãƒ³', 'ç ‚æµœ', 'æ°´æ—é¤¨', 'æµ·æ°´æµ´', 'çœŸç '],
        'mountain': ['å±±', 'ç™»å±±', 'ãƒã‚¤ã‚­ãƒ³ã‚°', 'å³ ', 'é«˜åŸ', 'å±±é ‚', 'æ¸“è°·', 'å±±ç™»ã‚Š'],
        'nature': ['è‡ªç„¶', 'æ™¯è‰²', 'çµ¶æ™¯', 'é¢¨æ™¯', 'ã‚¨ã‚³', 'æ£®', 'å…¬åœ’', 'èŠ±', 'ç´…è‘‰', 'æ˜Ÿç©º', 'å·'],
        'history': ['æ­´å²', 'æ–‡åŒ–', 'ä¼çµ±', 'å¯º', 'ç¥ç¤¾', 'åŸ', 'å¤ã„', 'éºè·¡', 'æ–‡åŒ–è²¡', 'ä¼Šå‹¢', 'æ­¦å°†', 'å¿è€…'],
        'play': ['éŠã¶', 'ä½“é¨“', 'ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£', 'ãƒ¬ã‚¸ãƒ£ãƒ¼', 'æ¥½ã—ã‚€', 'ãƒ†ãƒ¼ãƒãƒ‘ãƒ¼ã‚¯', 'å‹•ç‰©åœ’', 'éŠåœ’åœ°', 'æ°´æ—é¤¨'],
        'shopping': ['è²·ã„ç‰©', 'ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°', 'ãŠåœŸç”£', 'åº—', 'ãƒ¢ãƒ¼ãƒ«', 'å•†åº—è¡—', 'å¸‚å ´', 'ã‚¢ã‚¦ãƒˆãƒ¬ãƒƒãƒˆ', 'ç‰¹ç”£å“'],
        'food': ['é£Ÿã¹', 'ã‚°ãƒ«ãƒ¡', 'æ–™ç†', 'ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³', 'ç¾å‘³', 'ãŠã„ã—ã„', 'ã‚«ãƒ•ã‚§', 'é£Ÿäº‹', 'ãƒ©ãƒ³ãƒ', 'åç‰©', 'é£Ÿã¹æ­©ã', 'æ¾é˜ªç‰›', 'ä¼Šå‹¢æµ·è€'],
        'family': ['å®¶æ—', 'å­ä¾›', 'ãƒ•ã‚¡ãƒŸãƒªãƒ¼', 'è¦ªå­', 'å­ã©ã‚‚', 'ã‚­ãƒƒã‚º', 'èµ¤ã¡ã‚ƒã‚“', '3ä¸–ä»£'],
        'rain': ['é›¨', 'å±‹å†…', 'ã‚¤ãƒ³ãƒ‰ã‚¢', 'é›¨å¤©', 'å®¤å†…', 'å¤©å€™', 'æ¿¡ã‚Œãªã„', 'é›¨ã®æ—¥', 'åšç‰©é¤¨', 'ç¾è¡“é¤¨']
    }
    
    adjusted_scores = scores.copy()
    
    for label in label_names:
        if label in keyword_boost:
            for keyword in keyword_boost[label]:
                if keyword in text:
                    adjusted_scores[label] *= 1.8  # ãƒ–ãƒ¼ã‚¹ãƒˆå€ç‡
                    break
    
    return adjusted_scores



def predict_labels(text, threshold=0.5):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)

    with torch.no_grad():
        outputs = model(**inputs)

    probs = torch.sigmoid(outputs.logits)[0].cpu().numpy()

    scores = {label_names[i]: float(probs[i]) for i in range(len(label_names))}
    
    # â˜…ã“ã“ã§ã‚¹ã‚³ã‚¢èª¿æ•´ã‚’é©ç”¨â˜…
    scores = adjust_scores_by_keywords(text, scores, label_names)    
    
    active = [k for k, v in scores.items() if v >= threshold]

    return scores, active



# =====================
# CSV èª­ã¿è¾¼ã¿
# =====================
spots_df = pd.read_csv("data/mie_spot.csv")
# â†“ ã“ã“ã‚’è¿½åŠ ï¼šã‚«ãƒ©ãƒ åã®å‰å¾Œã®ç©ºç™½ã‚’å‰Šé™¤ã—ã€ä¸€å¾‹ã§ã‚¯ãƒªãƒ¼ãƒ³ã«ã™ã‚‹
spots_df.columns = spots_df.columns.str.strip()

hotels_df = pd.read_csv("data/mie_hotel.csv")
# â†“ ã¤ã„ã§ã«ãƒ›ãƒ†ãƒ«å´ã‚‚ã‚„ã£ã¦ãŠãã¨å®‰å…¨ã§ã™
hotels_df.columns = hotels_df.columns.str.strip()

NAGOYA = {"name": "åå¤å±‹é§…", "lat": 35.1709, "lon": 136.8815}


# =====================
# UIï¼šæ–‡ç« å…¥åŠ›
# =====================
st.header("â‘  è¡ŒããŸã„æ—…è¡Œã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’å…¥åŠ›")

text = st.text_area(
    "ä¾‹ï¼šé›¨ã®æ—¥ã§ã‚‚å®¶æ—ã§æ¥½ã—ã‚ã‚‹å ´æ‰€ã«è¡ŒããŸã„",
    height=80
)

if not text:
    st.stop()


# =====================
# è¦³å…‰åœ°ã‚¹ã‚³ã‚¢è¨ˆç®—
# =====================
scores, active_labels = predict_labels(text)

st.subheader("ğŸ” æ¨å®šã•ã‚ŒãŸæ—…è¡Œã‚¿ã‚¤ãƒ—")
st.write(active_labels)

spot_ranking = calc_spot_scores(scores, spots_df)
if spot_ranking.empty:
    st.error("æ¡ä»¶ã«åˆã†è¦³å…‰åœ°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    st.stop()

top_spots = spot_ranking.head(4)


# =====================
# è¦³å…‰åœ°è¡¨ç¤º
# =====================
st.header("â‘¡ ãŠã™ã™ã‚è¦³å…‰åœ°")

cols = st.columns(2)
for i, (_, row) in enumerate(top_spots.iterrows()):
    with cols[i % 2]:
        st.subheader(row["spot_name"])
        # if "img_url" in row:
            # st.image(row["img_url"], use_column_width=True)
        st.write(row["description"])     
        st.write(f"ã‚¹ã‚³ã‚¢ï¼š{row['score']:.2f}")


# =====================
# ãƒ›ãƒ†ãƒ«æ¡ä»¶
# =====================
st.header("â‘¢ å®¿æ³Šæ¡ä»¶")

col1, col2, col3 = st.columns(3)

with col1:
    family = st.checkbox("å®¶æ—å‘ã‘")
    couple = st.checkbox("ã‚«ãƒƒãƒ—ãƒ«")
    kids_room = st.checkbox("ã‚­ãƒƒã‚ºãƒ«ãƒ¼ãƒ ã‚ã‚Š")
    quiet = st.checkbox("é™ã‹ãªå ´æ‰€")


with col2:
    scenic = st.checkbox("æ™¯è‰²ãŒè‰¯ã„")
    beach_front = st.checkbox("æµ·ãŒç›®ã®å‰")
    hot_spring = st.checkbox("æ¸©æ³‰")
    ocean_view_bath = st.checkbox("æµ·ã®è¦‹ãˆã‚‹ãŠé¢¨å‘‚")
    private_dining = st.checkbox("éƒ¨å±‹é£Ÿã‚ã‚Š") 

with col3:
    near_station = st.checkbox("é§…è¿‘")
    glamping = st.checkbox("ã‚°ãƒ©ãƒ³ãƒ”ãƒ³ã‚°")
    ise_shima_access = st.checkbox("ä¼Šå‹¢å¿—æ‘©è¦³å…‰ã«ä¾¿åˆ©")
    shopping = st.checkbox("è²·ã„ç‰©ä¾¿åˆ©")

    
user_hotel_pref = {
    "family": int(family),
    "couple": int(couple),
    "hot_spring": int(hot_spring),
    "scenic": int(scenic),
    "near_station": int(near_station),
    "glamping": int(glamping),
    "shopping": int(shopping),
    "ocean_view_bath": int(ocean_view_bath),
    "quiet": int(quiet),
    "ise_shima_access": int(ise_shima_access),
    "beach_front": int(beach_front),
    "kids_room": int(kids_room),
    "private_dining": int(private_dining)
    

}

ranked_hotels = rank_hotels(hotels_df, user_hotel_pref)
hotel = ranked_hotels.iloc[0]

st.success(f"ğŸ¨ ãŠã™ã™ã‚å®¿æ³Šæ–½è¨­ï¼š{hotel['name']}ï¼ˆ{hotel['area']}ï¼‰")
st.write(hotel["description"])


# =====================
# Day1 / Day2 åˆ†å‰²
# =====================
day1_df = top_spots.iloc[:2]
day2_df = top_spots.iloc[2:]

hotel_location = {
    "name": hotel["name"],
    "lat": hotel["lat"],
    "lon": hotel["lon"]
}

# ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆï¼šCSVã® "spot_name" ã‚’ "name" ã«ãƒªãƒãƒ¼ãƒ ã—ã¦ã‹ã‚‰æŠ½å‡ºã™ã‚‹
day1_locations = (
    [NAGOYA] +
    day1_df[["spot_name", "lat", "lon"]].rename(columns={"spot_name": "name"}).to_dict("records") +
    [hotel_location]
)

day2_locations = (
    [hotel_location] +
    day2_df[["spot_name", "lat", "lon"]].rename(columns={"spot_name": "name"}).to_dict("records") +
    [NAGOYA]
)


# Day1ï¼šåå¤å±‹ã‚¹ã‚¿ãƒ¼ãƒˆ â†’ ãƒ›ãƒ†ãƒ«ã‚´ãƒ¼ãƒ«
day1_route = solve_tsp(day1_locations, start_index=0, end_index=len(day1_locations)-1)

# Day2ï¼šãƒ›ãƒ†ãƒ«ã‚¹ã‚¿ãƒ¼ãƒˆ â†’ åå¤å±‹ã‚´ãƒ¼ãƒ«
day2_route = solve_tsp(day2_locations, start_index=0, end_index=len(day2_locations)-1)



# =====================
# ãƒ«ãƒ¼ãƒˆè¡¨ç¤º
# =====================
st.header("â‘£ 1æ³Š2æ—¥ãƒ¢ãƒ‡ãƒ«ãƒ«ãƒ¼ãƒˆ")

# googlemapã‚¯ãƒªãƒƒã‚¯è¡¨ç¤º
st.subheader("ğŸ—“ Day1")
st.write(" â†’ ".join(day1_route))
st.markdown(f"[Googleãƒãƒƒãƒ—ã§é–‹ã]({make_google_map_url(day1_route)})")

st.subheader("ğŸ—“ Day2")
st.write(" â†’ ".join(day2_route))
st.markdown(f"[Googleãƒãƒƒãƒ—ã§é–‹ã]({make_google_map_url(day2_route)})")

